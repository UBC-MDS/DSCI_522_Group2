{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'myst_nb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/ellahein/Desktop/UBC_Coursework/DSCI522/project/DSCI_522_Group2/report/diabetes_classification_model_report.ipynb Cell 1\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ellahein/Desktop/UBC_Coursework/DSCI522/project/DSCI_522_Group2/report/diabetes_classification_model_report.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ellahein/Desktop/UBC_Coursework/DSCI522/project/DSCI_522_Group2/report/diabetes_classification_model_report.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ellahein/Desktop/UBC_Coursework/DSCI522/project/DSCI_522_Group2/report/diabetes_classification_model_report.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmyst_nb\u001b[39;00m \u001b[39mimport\u001b[39;00m glue\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'myst_nb'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from myst_nb import glue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/ellahein/Desktop/UBC_Coursework/DSCI522/project/DSCI_522_Group2/report/diabetes_classification_model_report.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ellahein/Desktop/UBC_Coursework/DSCI522/project/DSCI_522_Group2/report/diabetes_classification_model_report.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Define variables with glue here\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ellahein/Desktop/UBC_Coursework/DSCI522/project/DSCI_522_Group2/report/diabetes_classification_model_report.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m scores_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39m../results/tables/model_comparison_results.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ellahein/Desktop/UBC_Coursework/DSCI522/project/DSCI_522_Group2/report/diabetes_classification_model_report.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m glue(\u001b[39m\"\u001b[39m\u001b[39mdt_test_score\u001b[39m\u001b[39m\"\u001b[39m, scores_df\u001b[39m.\u001b[39mloc[\u001b[39m'\u001b[39m\u001b[39mDecision tree\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m'\u001b[39m]) \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ellahein/Desktop/UBC_Coursework/DSCI522/project/DSCI_522_Group2/report/diabetes_classification_model_report.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m glue(\u001b[39m\"\u001b[39m\u001b[39mlr_test_score\u001b[39m\u001b[39m\"\u001b[39m, scores_df\u001b[39m.\u001b[39mloc[\u001b[39m'\u001b[39m\u001b[39mLogistic regression\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Define variables with glue here\n",
    "scores_df = pd.read_csv(\"../results/tables/model_comparison_results.csv\")\n",
    "glue(\"dt_test_score\", scores_df.loc['Decision tree', 'test_score']) \n",
    "glue(\"lr_test_score\", scores_df.loc['Logistic regression', 'test_score'])\n",
    "glue(\"dummy_score\", scores_df.loc['Dummy', 'test_score'])\n",
    "glue(\"model_score_table\", scores_df, display=False)\n",
    "\n",
    "coef_df = pd.read_csv(\"../results/tables/model_comparison_results.csv\").round(2).sort_values(by='coefficients', ascending=False)\n",
    "glue(\"coef_table\", coef_df, display=False)\n",
    "feature_importance_df = pd.read_csv(\"../results/tables/feature_importances.csv\").round(3)\n",
    "model_comparison_df = pd.read_csv(\"../results/tables/model_comparison_results.csv\").round(3)\n",
    "confusion_matrix_dt = pd.read_csv(\"../results/tables/confusion_matrix_DT.csv\")\n",
    "glue(\"highest_importance_coeff\", feature_importance_df.iloc[4,2],display=False)\n",
    "glue(\"optimized_knn_test_score\", model_comparison_df.iloc[3,3],display=False)\n",
    "glue(\"dt_test_score\", model_comparison_df.iloc[1,3],display=False)\n",
    "glue(\"false_negative\", confusion_matrix_dt.iloc[1,1],display=False)\n",
    "glue(\"false_positive\", confusion_matrix_dt.iloc[0,2],display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "This project endeavors to develop a predictive classification model for ascertaining an individual's diabetic status, while comparing the efficiency of optimized decision tree and optimized k-nearest neighbours (k-nn) algorithms. The dataset used in this analysis is collected through the Behavioral Risk Factor Surveillance System (BFRSS) by the Centers for Disease Control and Prevention (CDC) for the year 2015. Notably, the primary determinant influencing the prediction is identified as the feature Body Mass Index (BMI), displaying a coefficient of {glue:text}`highest_importance_coeff`  as revealed by the logistic regression model. The optimized decision tree model demonstrates a test score of {glue:text}`dt_test_score`,while the optimized k-nn model yields a test score of {glue:text}`optimized_knn_test_score`. Both of the test scores are relatively close to the validation score which shows that the model will generalized well to unseen data, however, there is still room for improvement in the test score. \n",
    "\n",
    "Our final classsifer is chosen to be the Desicion Tree model as it has both the highest test and train score in comparison with the optimized k-nn model. However, from the confusion matrix, we can see that our model has made {glue:text}`false_negative` type II error, which predicted the individual as non-diabetic when they are actually diabetic. On the other hand, it has also made {glue:text}`false_positive` type I error, which predicted the individual as diabetic when they are actually non-diabetic. In our case, both type II error and type I error is equivalently important as injecting insulin in a non-diabetic individual can be fatal and vice versa. Hence, we chose f1 score as our scoring matrix which is a hormonic balance between both type I and type II errors. From this result, we can also see that there is a huge class imbalance in between diabetic and non-diabetic class, which will be taken into account in the preprocessor in the next version of this analysis.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Diabetes mellitus, commonly referred to as diabetes is a disease which impacts the bodyâ€™s control of blood glucose levels (Sapra, Bhandari 2023). It is important to note that there are different types of diabetes, although we do not explore this discrepancy in this project (Sapra, Bhandari 2023). Diabetes is a manageable disease thanks to the discovery of insulin in 1922. Globally, 1 in 11 adults have diabetes (Sapra, Bhandari 2023). As such, understanding the factors which are strongly related to diabetes can be important for researchers studying how to better prevent or manage the disease. In this project, we create several machine learning models to predict diabetes in a patient and evaluate the success of these models. We also explore the coefficients of a logistic regression model to better understand the factors which are associated with diabetes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "\n",
    "### Data\n",
    "The dataset used in this project is a collection of the Centers for Disease Control and Prevention (CDC) diabetes health indicators collected as a response to the CDC's BRFSS2015 survey. The data were sourced from the UCI Machine Learning Repository (Burrows, Hora, Geiss, Gregg, and Albright 2017) which can be found [here](https://archive.ics.uci.edu/dataset/891/cdc+diabetes+health+indicators). The file specifically used from this repository for this analysis includes 70, 692 survey responses from which 50% of the respondents recorded having either prediabetes or diabetes. Each row in the dataset represents a recorded survey response including whether or not the responded has diabetes or prediabetes, and a collection of 21 other diabetes health indicators identified by the CDC. \n",
    "\n",
    "### Analysis\n",
    "In our efforts to determine the best model for classifying a patient with diabetes or prediabetes as opposed to no diabetes or prediabetes, we performed hyperparamter optimization on both a knn model and a decision tree model. We also explored a logistic regression model to gain insight into which features may contribute most to a classification of diabetes. All features from the original dataset were included in each model. In all cases, the data were split into training and testing datasets, with 80% of the data designated as training and 20% as testing. The data was preprocessesed such that all continuous (non-binary) variables were scaled using a scikit-learn's StandardScaler function. Model performance was tested using a 10 - fold cross validation score. Feature importance was investigated using the coefficients generated by the logistic regression algorithm. The k-nn algorithm's hyperparameter K was optimized using the F1 score as the classification metric. Python programming (Van Rossum and Drake 2009) was used for all analysis. The following Python packages were used for this analysis: Pandas (McKinney 2010), altair (VanderPlas, 2018), and scikit-learn (Pedregosa et al. 2011).\n",
    "\n",
    "### Results & Discussion\n",
    "\n",
    "Before we  begin building our models for comparison, we plotted the histogram distribution of each feature in the dataset to have an insight on the features. used with 0 and 1 representing the non-diabetic class(blue) and the diabetic class(orange) respectively  {numref}`Figure {number} <feature_histogram_by_class.png>`. It is seen that for all the features, there is a significant overlapping in between the classes as most of the features are binary features. However, their max and mean values for each feature seems to be different, thus, we decided to include all the features in our model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../results/figures/feature_histogram_by_class.png\n",
    "---\n",
    "width: 800px\n",
    "name: feature_histogram_by_class\n",
    "---\n",
    "Histogram distribution for each feature in the training data for both non-diabetic (0 & blue) and diabetic (1 & orange) class.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through using a random search we performed hyper parameter optimization on a knn model and a decision tree model. \n",
    "The table below, ({numref}`Figure {number} <knn_tree_cross_val>`) shows the results of performing cross validation on the best performing knn and decision tree models, respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then compared the two optimized models to a dummy classifier and a logistic regression model. The optimized decision tree model out-performed all others, with a cross validation score of {glue:text} `dt_test_score`. As seen in the table below  ({numref}`Figure {number} <model_score_table>`), all of the scores were quite high for all models, even the dummy model. This is likely due to the imbalance in the target features, which should be addressed if this model were to be improved and used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    ":figwidth: 400px\n",
    ":name: \"model_score_table\"\n",
    "\n",
    "Cross validation results for all optimized models, as a result of a random search hyperparamater optimization, compared to a dummy classifier.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the logistic regression model did not have the best performance compared to the other models, with a cross-validation score of {glue:text} {glue:text}`lr_test_score` its coefficients were still useful in investigating which features were weighted as more important in indicating whether a person has diabetes/prediabetes. The results, shown in the table below ({numref}`Figure {number} <coef_table>`), indicate that general health (GenHlth), is the largest predictor of diabetes/prediabetes, followed by body mass index (BMI), high blood pressure (HighBP), and age, respectively. All of these factors, unsurprisingly had a positive correlation with the presence of diabetes/prediabetes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    ":figwidth: 200px\n",
    ":name: \"coef_table\"\n",
    "\n",
    "Logistic regression coefficients by feature.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "```{bibliography}```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
